{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cpu\n"
     ]
    }
   ],
   "source": [
    "# https://bamblebam.medium.com/audio-classification-and-regression-using-pytorch-48db77b3a5ec\n",
    "# The above code will import all the necessary libraries and initialize your device to either CPU or GPU. \n",
    "\n",
    "import torchaudio as ta\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as numpy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "\n",
    "import cnn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('yes')\n",
    "    device='cuda'\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "import torch\n",
    "from cnn import CNNetwork\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import itertools\n",
    "\n",
    "import nussl\n",
    "from importlib import reload \n",
    "import nussl_fram\n",
    "reload (nussl_fram)\n",
    "\n",
    "from nussl_fram import dataset_v3\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 samples in the data\n"
     ]
    }
   ],
   "source": [
    "nussl.utils.seed(0)  # make sure this does the same thing each time\n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=256, hop_length=64)\n",
    "tfm = nussl.datasets.transforms.Compose([\n",
    "    nussl.datasets.transforms.PhaseSensitiveSpectrumApproximation(),\n",
    "    nussl.datasets.transforms.MagnitudeWeights(),\n",
    "    nussl.datasets.transforms.ToSeparationModel()\n",
    "])\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"audio\")\n",
    "# TODO - update to 44100\n",
    "uds = dataset_v3(path, sample_rate=8000, stft_params=stft_params, transform=tfm)\n",
    "print(f\"There are {len(uds)} samples in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['index', 'mix_magnitude', 'ideal_binary_mask', 'source_magnitudes', 'weights'])\n",
      "torch.Size([626, 129, 1])\n"
     ]
    }
   ],
   "source": [
    "item = uds[0]\n",
    "print(item.keys())\n",
    "print(item['mix_magnitude'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sources'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m      9\u001b[0m     nussl\u001b[39m.\u001b[39mplay_utils\u001b[39m.\u001b[39mmultitrack(sources, ext\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m visualize_and_embed(item[\u001b[39m'\u001b[39;49m\u001b[39msources\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(item[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sources'"
     ]
    }
   ],
   "source": [
    "def visualize_and_embed(sources, y_axis='mel'):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(111)\n",
    "    nussl.utils.visualize_sources_as_masks(\n",
    "        sources, db_cutoff=-60, y_axis=y_axis)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    nussl.play_utils.multitrack(sources, ext='.wav')\n",
    "\n",
    "\n",
    "visualize_and_embed(item['sources'])\n",
    "print(item['metadata'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://source-separation.github.io/tutorial/training/putting_it_all_together.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 samples in the data\n",
      "There are 30 samples in the train data\n",
      "There are 10 samples in the test data\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = train_test_split(uds, test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "print(f\"There are {len(train_data)} samples in the train data\")\n",
    "print(f\"There are {len(test_data)} samples in the test data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "item = train_data[0]\n",
    "for key in item:\n",
    "    if torch.is_tensor(item[key]):\n",
    "        item[key] = item[key].float().unsqueeze(0)\n",
    "output = model(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in output:\n",
    "    print(key, type(output[key]), output[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.verbose = True\n",
    "output = model(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeparationModel(\n",
      "  (layers): ModuleDict(\n",
      "    (model): Mask_eliment(\n",
      "      (amplitude_to_db): AmplitudeToDB()\n",
      "      (input_normalization): BatchNorm(\n",
      "        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (recurrent_stack): RecurrentStack(\n",
      "        (rnn): LSTM(257, 50, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "      )\n",
      "      (embedding): Embedding(\n",
      "        (linear): Linear(in_features=100, out_features=771, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask): Alias()\n",
      "    (estimates): Alias()\n",
      "  )\n",
      ")\n",
      "Number of parameters: 262273\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "nf = stft_params.window_length // 2 + 1\n",
    "nac = 1\n",
    "model = Mask_eliment.build(num_audio_channels = nf,\n",
    "                           num_features = nac,\n",
    "                           hidden_size = 50,\n",
    "                           num_layers = 2,\n",
    "                           bidirectional = True,\n",
    "                           dropout = 0.1,\n",
    "                           num_sources = 3,\n",
    "                           activation = 'sigmoid')\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "\n",
    "def train_step(batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    \n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item() # return the loss for bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mix_magnitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m pbar \u001b[39m=\u001b[39m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mrange\u001b[39m(N_ITERATIONS))\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m---> 16\u001b[0m     loss_val \u001b[39m=\u001b[39m train_step(batch)\n\u001b[0;32m     17\u001b[0m     loss_history\u001b[39m.\u001b[39mappend(loss_val)\n\u001b[0;32m     18\u001b[0m     pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss_val\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(batch):\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m     output \u001b[39m=\u001b[39m model(batch) \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(\n\u001b[0;32m     21\u001b[0m         output[\u001b[39m'\u001b[39m\u001b[39mestimates\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     22\u001b[0m         batch[\u001b[39m'\u001b[39m\u001b[39msource_magnitudes\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     loss\u001b[39m.\u001b[39mbackward() \u001b[39m# backwards + gradient step\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nussl\\ml\\networks\\separation_model.py:179\u001b[0m, in \u001b[0;36mSeparationModel.forward\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m                     kwargs[key] \u001b[39m=\u001b[39m val\n\u001b[0;32m    178\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m             input_data\u001b[39m.\u001b[39mappend(output[c] \u001b[39mif\u001b[39;00m c \u001b[39min\u001b[39;00m output \u001b[39melse\u001b[39;00m data[c])\n\u001b[0;32m    181\u001b[0m _output \u001b[39m=\u001b[39m layer(\u001b[39m*\u001b[39minput_data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m added_keys \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mix_magnitude'"
     ]
    }
   ],
   "source": [
    "# Comment out the line above to see the output\n",
    "# of this cell in Colab or Jupyter Notebook\n",
    "import tqdm\n",
    "\n",
    "item = train_data[0] # Because of the transforms, this produces tensors.\n",
    "batch = {} # A batch of size 1, in this case. Usually we'd have more.\n",
    "for key in item:\n",
    "    if torch.is_tensor(item[key]):\n",
    "        batch[key] = item[key].float().unsqueeze(0)\n",
    "    \n",
    "N_ITERATIONS = 100\n",
    "loss_history = [] # For bookkeeping\n",
    "\n",
    "pbar = tqdm.tqdm(range(N_ITERATIONS))\n",
    "for _ in pbar:\n",
    "    loss_val = train_step(batch)\n",
    "    loss_history.append(loss_val)\n",
    "    pbar.set_description(f'Loss: {loss_val:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Train loss history of our model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    \n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item()\n",
    "    }\n",
    "    \n",
    "    return loss_vals # return the loss for bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )    \n",
    "    loss_vals = {'L1Loss': loss.item()}\n",
    "    return loss_vals # return the loss for bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 samples in the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current run is terminating due to exception: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>\n",
      "Engine run is terminating due to exception: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 samples in the train data\n",
      "There are 10 samples in the test data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:146\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed])\n\u001b[0;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:146\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed])\n\u001b[0;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:151\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:128\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[0;32m    129\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:128\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[0;32m    129\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:149\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m    151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:149\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m    151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:151\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:146\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed])\n\u001b[0;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:146\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed])\n\u001b[0;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:151\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 95\u001b[0m\n\u001b[0;32m     91\u001b[0m nussl\u001b[39m.\u001b[39mml\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39madd_stdout_handler(trainer, validator)\n\u001b[0;32m     92\u001b[0m nussl\u001b[39m.\u001b[39mml\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39madd_validate_and_checkpoint(output_folder, model, \n\u001b[0;32m     93\u001b[0m     optimizer, train_data, trainer, test_dataloder, validator)\n\u001b[1;32m---> 95\u001b[0m trainer\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m     96\u001b[0m     train_dataloader, \n\u001b[0;32m     97\u001b[0m     epoch_length\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[0;32m     98\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m     99\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:892\u001b[0m, in \u001b[0;36mEngine.run\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mdataloader \u001b[39m=\u001b[39m data\n\u001b[0;32m    891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterrupt_resume_enabled:\n\u001b[1;32m--> 892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run()\n\u001b[0;32m    893\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:935\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_as_gen()\n\u001b[0;32m    934\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run_generator)\n\u001b[0;32m    936\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m out:\n\u001b[0;32m    937\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:993\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEngine run is terminating due to exception: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 993\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_exception(e)\n\u001b[0;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    996\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[0;32m    637\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 638\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:959\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_engine()\n\u001b[1;32m--> 959\u001b[0m epoch_time_taken \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[0;32m    961\u001b[0m \u001b[39m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtimes[Events\u001b[39m.\u001b[39mEPOCH_COMPLETED\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m epoch_time_taken\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:1087\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent run is terminating due to exception: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_exception(e)\n\u001b[0;32m   1089\u001b[0m \u001b[39mreturn\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[0;32m    637\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 638\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ignite\\engine\\engine.py:1032\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mGET_BATCH_STARTED)\n\u001b[0;32m   1030\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[1;32m-> 1032\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataloader_iter)\n\u001b[0;32m   1033\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mGET_BATCH_COMPLETED)\n\u001b[0;32m   1034\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:131\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[0;32m    129\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[0;32m    132\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:131\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[0;32m    129\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[0;32m    132\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:149\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[39mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed])\n\u001b[0;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m    151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:149\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[39mreturn\u001b[39;00m elem_type([collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed])\n\u001b[0;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m    151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py:151\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'nussl.core.audio_signal.AudioSignal'>"
     ]
    }
   ],
   "source": [
    "import nussl\n",
    "import torch\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "from pathlib import Path\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MAX_MIXTURES = int(1e8) # We'll set this to some impossibly high number for on the fly mixing.\n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n",
    "\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['frog', 'hen', 'pig']]),\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from nussl_fram import dataset_v3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"audio\")\n",
    "uds = dataset_v3(path)\n",
    "print(f\"There are {len(uds)} samples in the data\")\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = train_test_split(uds, test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "print(f\"There are {len(train_data)} samples in the train data\")\n",
    "print(f\"There are {len(test_data)} samples in the test data\")\n",
    "\n",
    "# Create data loader for the train data\n",
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader\n",
    "\n",
    "# Create train loader\n",
    "train_dataloader = create_data_loader(train_data, BATCH_SIZE)\n",
    "\n",
    "# Create test loader\n",
    "test_dataloder = create_data_loader(test_data, BATCH_SIZE)\n",
    "\n",
    "nf = stft_params.window_length // 2 + 1\n",
    "model = Mask_eliment.build(nf, 1, 50, 1, True, 0.0, 1, 'sigmoid')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )\n",
    "    \n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    \n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_magnitudes']\n",
    "    )    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(), \n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals\n",
    "\n",
    "# Create the engines\n",
    "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
    "    train_step, val_step, device=DEVICE\n",
    ")\n",
    "\n",
    "# We'll save the output relative to this notebook.\n",
    "output_folder = Path('.').absolute()\n",
    "\n",
    "# Adding handlers from nussl that print out details about model training\n",
    "# run the validation step, and save the models.\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
    "    optimizer, train_data, trainer, test_dataloder, validator)\n",
    "\n",
    "trainer.run(\n",
    "    train_dataloader, \n",
    "    epoch_length=10, \n",
    "    max_epochs=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
